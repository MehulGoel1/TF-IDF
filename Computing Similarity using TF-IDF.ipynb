{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computing Similarity using td-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('me', 2), ('Julie', 1), ('loves', 2), ('Linda', 1), ('than', 1), ('more', 1)]\n",
      "[('me', 2), ('Julie', 1), ('likes', 1), ('loves', 1), ('Jane', 1), ('than', 1), ('more', 1)]\n",
      "[('basketball', 1), ('baseball', 1), ('likes', 1), ('He', 1), ('than', 1), ('more', 1)]\n"
     ]
    }
   ],
   "source": [
    "mydoclist = ['Julie loves me more than Linda loves me',\n",
    "'Jane likes me more than Julie loves me',\n",
    "'He likes basketball more than baseball ']\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "for doc in mydoclist:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] +=1\n",
    "    print tf.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [me, basketball, Julie, baseball, likes, loves, Jane, Linda, He, than, more]\n",
      "The doc is \"Julie loves me more than Linda loves me\"\n",
      "The tf vector for Document 1 is [2, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1]\n",
      "The doc is \"Jane likes me more than Julie loves me\"\n",
      "The tf vector for Document 2 is [2, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
      "The doc is \"He likes basketball more than baseball\"\n",
      "The tf vector for Document 3 is [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "All combined, here is our master document term matrix: \n",
      "[[2, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1], [2, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "import string #allows for format()\n",
    "    \n",
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "def tf(term, document):\n",
    "  return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "  return document.split().count(term)\n",
    "\n",
    "vocabulary = build_lexicon(mydoclist)\n",
    "\n",
    "doc_term_matrix = []\n",
    "print 'Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']'\n",
    "for doc in mydoclist:\n",
    "    print 'The doc is \"' + doc + '\"'\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    print 'The tf vector for Document %d is [%s]' % ((mydoclist.index(doc)+1), tf_vector_string)\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "    \n",
    "    # here's a test: why did I wrap mydoclist.index(doc)+1 in parens?  it returns an int...\n",
    "    # try it!  type(mydoclist.index(doc) + 1)\n",
    "\n",
    "print 'All combined, here is our master document term matrix: '\n",
    "print doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A regular old document term matrix: \n",
      "[[2 0 1 0 0 2 0 1 0 1 1]\n",
      " [2 0 1 0 1 1 1 0 0 1 1]\n",
      " [0 1 0 1 1 0 0 0 1 1 1]]\n",
      "\n",
      "A document term matrix with row-wise L2 norms of 1:\n",
      "[[ 0.57735027  0.          0.28867513  0.          0.          0.57735027\n",
      "   0.          0.28867513  0.          0.28867513  0.28867513]\n",
      " [ 0.63245553  0.          0.31622777  0.          0.31622777  0.31622777\n",
      "   0.31622777  0.          0.          0.31622777  0.31622777]\n",
      " [ 0.          0.40824829  0.          0.40824829  0.40824829  0.          0.\n",
      "   0.          0.40824829  0.40824829  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def l2_normalizer(vec):\n",
    "    denom = np.sum([el**2 for el in vec])\n",
    "    return [(el / math.sqrt(denom)) for el in vec]\n",
    "\n",
    "doc_term_matrix_l2 = []\n",
    "for vec in doc_term_matrix:\n",
    "    doc_term_matrix_l2.append(l2_normalizer(vec))\n",
    "\n",
    "print 'A regular old document term matrix: ' \n",
    "print np.matrix(doc_term_matrix)\n",
    "print '\\nA document term matrix with row-wise L2 norms of 1:'\n",
    "print np.matrix(doc_term_matrix_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [me, basketball, Julie, baseball, likes, loves, Jane, Linda, He, than, more]\n",
      "The inverse document frequency vector is [1.609438, 1.386294, 1.609438, 1.386294, 1.609438, 1.609438, 1.386294, 1.386294, 1.386294, 1.791759, 1.791759]\n"
     ]
    }
   ],
   "source": [
    "def numDocsContaining(word, doclist):\n",
    "    doccount = 0\n",
    "    for doc in doclist:\n",
    "        if freq(word, doc) > 0:\n",
    "            doccount +=1\n",
    "    return doccount \n",
    "\n",
    "def idf(word, doclist):\n",
    "    n_samples = len(doclist)\n",
    "    df = numDocsContaining(word, doclist)\n",
    "    return np.log(n_samples / 1+df)\n",
    "\n",
    "my_idf_vector = [idf(word, mydoclist) for word in vocabulary]\n",
    "\n",
    "print 'Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']'\n",
    "print 'The inverse document frequency vector is [' + ', '.join(format(freq, 'f') for freq in my_idf_vector) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_idf_matrix(idf_vector):\n",
    "    idf_mat = np.zeros((len(idf_vector), len(idf_vector)))\n",
    "    np.fill_diagonal(idf_mat, idf_vector)\n",
    "    return idf_mat\n",
    "\n",
    "my_idf_matrix = build_idf_matrix(my_idf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['me', 'basketball', 'Julie', 'baseball', 'likes', 'loves', 'Jane', 'Linda', 'He', 'than', 'more'])\n",
      "[[ 0.57211257  0.          0.28605628  0.          0.          0.57211257\n",
      "   0.          0.24639547  0.          0.31846153  0.31846153]]\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix_tfidf = []\n",
    "\n",
    "#performing tf-idf matrix multiplication\n",
    "for tf_vector in doc_term_matrix:\n",
    "    doc_term_matrix_tfidf.append(np.dot(tf_vector, my_idf_matrix))\n",
    "\n",
    "#normalizing\n",
    "doc_term_matrix_tfidf_l2 = []\n",
    "for tf_vector in doc_term_matrix_tfidf:\n",
    "    doc_term_matrix_tfidf_l2.append(l2_normalizer(tf_vector))\n",
    "                                    \n",
    "print vocabulary\n",
    "print np.matrix(doc_term_matrix_tfidf_l2)\n",
    "\n",
    "# np.matrix() just to make it easier to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57211257  0.          0.28605628  0.          0.          0.57211257\n",
      "   0.          0.24639547  0.          0.31846153  0.31846153]\n",
      " [ 0.62558902  0.          0.31279451  0.          0.31279451  0.31279451\n",
      "   0.26942653  0.          0.          0.34822873  0.34822873]\n",
      " [ 0.          0.36063612  0.          0.36063612  0.41868557  0.          0.\n",
      "   0.          0.36063612  0.46611542  0.46611542]]\n"
     ]
    }
   ],
   "source": [
    "y = np.matrix(doc_term_matrix_tfidf_l2)\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.55112111240998818, 1.185850194944025], [0.55112111240998818, 0.0, 1.0434633558003232], [1.185850194944025, 1.0434633558003232, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "for i in range(len(y)):\n",
    "    row = []\n",
    "    for j in range(len(y)):\n",
    "        dist = np.linalg.norm(y[i]-y[j])\n",
    "        row.append(dist)\n",
    "    d.append(row)\n",
    "print d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
